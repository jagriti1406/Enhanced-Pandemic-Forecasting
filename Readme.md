# Enhanced Graph Neural Networks for Pandemic Forecasting

This project builds upon the original [Transfer Graph Neural Networks for Pandemic Forecasting](https://arxiv.org/abs/2009.08388) by integrating new features and methodologies as part of the **CS521 (Statistical Natural Language Processing)** course at the **University of Illinois Chicago** under Professor **Natalie Parde**.

---

## Abstract

Pandemic forecasting is a complex task requiring models that integrate diverse data sources. Traditional approaches often fail to adapt to the dynamic nature of pandemics. This project enhances the original GNN-based framework by incorporating **Large Language Models (LLMs)** for contextual understanding and improving time-series predictions. These advancements demonstrate significant improvements in accuracy, robustness, and interpretability.

---

## New Features and Contributions

This enhanced framework introduces the following features:

1. **Integration of LLM-Derived Contextual Embeddings**  
   - Added a module to extract and process contextual signals from news articles, social media posts, and policy documents.  
   - Enriched node features using embeddings generated by transformer-based models like BERT and sentiment analysis tools.  
   - Scaled and appended contextual features to GNN inputs.

2. **Quantized Time-Series Data for LLM Processing**  
   - Converted numeric time-series data into token-like formats using clustering techniques.  
   - Enabled LLMs to process structured numeric data, bridging the gap between structured and textual inputs.  

3. **Prompt Engineering for Region-Specific Predictions**  
   - Developed techniques for LLMs to generate region-specific forecasts using tailored prompts.  
   - Enhanced interpretability and domain alignment with GNN predictions.

4. **Improved GNN Architectures**  
   - Implemented advanced GNN variants like GAT with attention mechanisms and temporal modeling using LSTM layers.  
   - Enhanced the adaptability of models to changing pandemic dynamics.

5. **Comprehensive Validation**  
   - Empirically validated the new methods using COVID-19 data from Italian regions.  
   - Demonstrated performance improvements across multiple metrics (MAE, MSE, R²).

---

## Data Sources

- **Labels**  
   Ground truth for confirmed cases is sourced from open datasets for Italy, England, France, and Spain. Processed data is included in the `data` folder.

- **Graphs**  
   Mobility data derived from Facebook Data for Good disease prevention maps. Aggregated and anonymized mobility graphs are included for reproducibility.

- **Contextual Data**  
   Extracted from platforms like GNews, Twitter, and Reddit to provide rich insights into public sentiment and policy impacts.

---

## Input Data Format

### 1. Epidemiological Labels  
All country‑level case counts are preprocessed into CSVs under `data/{country}/labels.csv`.  
**Schema**:

| Column            | Type    | Description                                  |
|-------------------|---------|----------------------------------------------|
| `region_id`       | string  | NUTS3 region identifier (e.g. `cosenza`)     |
| `date`            | date    | Observation date (`YYYY-MM-DD`)              |
| `confirmed_cases` | integer | New confirmed COVID-19 cases                 |

---

### 2. Mobility Graphs  
Mobility data are saved as NumPy archives under `data/{country}/graphs/`.  
- **Filename**: `mobility_{start}_{end}.npz`  
- **Contents**:  
  - `row` (int array): source region indices  
  - `col` (int array): target region indices  
  - `weight` (float array): average daily flow  

---

### 3. Contextual Text Data  
Fetched via APIs and then preprocessed into per‑country CSVs under `data/{country}/context/`.  

#### a. API Endpoints & Parameters  
- **GNews API**  
  - `q`: query string (e.g. “COVID-19”)  
  - `lang`: language code (e.g. `en`)  
  - `from`/`to`: date range (`YYYY-MM-DD`)  
- **Twitter API** (`/2/tweets/search/recent`)  
  - `query`: keyword + region filter  
  - `start_time`/`end_time`: ISO datetimes  
- **Reddit (PRAW)**  
  - `subreddit`: e.g. `CoronavirusUK`  
  - `sort`: top \| hot \| new  

#### b. Post‑processing Schema  
After extraction, each CSV has:

| Column              | Type    | Description                                        |
|---------------------|---------|----------------------------------------------------|
| `text`              | string  | Combined title/content of article/tweet/post       |
| `date`              | date    | Publication date (`YYYY-MM-DD`)                    |
| `engagement_score`  | float   | Upvotes + comments (Reddit) or `1.0` by default     |
| `sentiment_score`   | float   | Sentiment polarity (–1.0 … +1.0)                   |


---

## Requirements

To run this project, ensure you have the following dependencies:

### Python Dependencies
- `numpy`
- `pandas`
- `scipy`
- `pytorch==1.5.1`
- `pytorch-geometric==1.5.0`
- `networkx==1.11`
- `sklearn`

### Additional Tools
- Sentiment analysis tools (e.g., VADER)
- Transformer-based models (e.g., BERT)

### OS-Specific Notes
For Mac users, use the specified versions:
- `torch 1.7.0`, `torch-cluster 1.5.9`, `torch-geometric 2.0.1`
- `torch-scatter 2.0.7`, `torch-sparse 0.6.12`, `torch-spline-conv 1.2.1`

---

## How to Run

Follow these steps to set up and run the project:

1. **Clone the Repository**  
   ```bash
   git clone <repository_url>
   cd <repository_directory>
   ```

2. **Install Dependencies**  
   ```bash
   pip install -r requirements.txt
   ```

3. **Run Data Preparation**  
   Process and align the datasets:  
   ```bash
   python preprocess.py
   ```

4. **Run the Model**  
   Execute the main experiments with the enhanced features:  
   ```bash
   python main.py
   python metalearn.py
   ```

5. **Generate Visualizations**  
   To create plots for error cases or performance metrics, use the visualization scripts provided in the `scripts` directory.

6. **Evaluate Performance**  
   Run evaluation metrics:  
   ```bash
   python evaluate.py
   ```

---

## Results

The enhanced methods demonstrate significant improvements in pandemic forecasting accuracy:
- **Method 1**: LLM-Augmented GNN reduced MAE by 3.06% and improved R² by 4.35%.  
- **Method 2**: Quantized Numeric Time-Series achieved an 8.70% improvement in R².

---

## Results / Output Structure

All forecast outputs live in your `results/` folder with filenames:

```
out_{CC}_{H}_{M}.csv
```

- **`CC`**: Country code (IT, FR, ES, UK)  
- **`H`**: Forecast horizon in days (e.g. 15, 16, …)  
- **`M`**: Model variant (0 = baseline GNN, 1 = LLM‑augmented GNN, etc.)

### CSV Schema

| Column | Type   | Description                                  |
|--------|--------|----------------------------------------------|
| `n`    | string | Region name (NUTS3 identifier)               |
| `o`    | float  | Predicted cases after `H` days               |
| `l`    | float  | Actual (ground‑truth) cases after `H` days   |

#### Example: `out_IT_15_1.csv`

```csv
n,o,l
cosenza,10.3691025,5.0
massa_carrara,37.578682,24.0
biella,34.9,7.0
la_spezia,13.569931,4.0
gorizia,2.3436844,7.0
vibo_valentia,0.0,0.0
```

---

## Citation

If you use this project or its methods in your research, please cite both the original paper and this enhanced framework:

```bibtex
@inproceedings{panagopoulos2020transfer,
  title={{Transfer Graph Neural Networks for Pandemic Forecasting}},
  author={Panagopoulos, George and Nikolentzos, Giannis and Vazirgiannis, Michalis},
  booktitle={Proceedings of the 35th AAAI Conference on Artificial Intelligence},
  year={2021},
}

@misc{Enhanced Graph Neural Networks for Pandemic Forecasting,
  title={Enhanced Graph Neural Networks for Pandemic Forecasting},
  author={Aman Laiq Mohammed, Jagriti Bhandari},
  year={2024},
}
```

---

## Acknowledgements

This project was developed as part of the **CS521: Statistical Natural Language Processing** course at the **University of Illinois Chicago**, under the guidance of Professor **Natalie Parde**.
```